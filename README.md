# AI Assistant

A ChatGPT-lite clone built with Bun, Vite, React, TypeScript, and Tailwind CSS.

## Features

- ğŸš€ **Streaming responses** - See AI responses in real-time as they're generated
- ğŸ¨ **Clean Chat UI** - User and AI message bubbles with smooth scrolling
- âš™ï¸ **Custom System Prompts** - Configure the AI's behavior/personality
- ğŸ”’ **Secure** - API key stays on the server, never exposed to the client

## Tech Stack

- **Runtime/Package Manager**: Bun
- **Frontend**: Vite + React + TypeScript + Tailwind CSS
- **Backend**: Bun HTTP server (Bun.serve)
- **AI**: OpenAI API (gpt-4o-mini)

## Getting Started

### Prerequisites

- [Bun](https://bun.sh/) installed
- OpenAI API key

### Installation

1. Clone the repository

2. Install dependencies:
   ```bash
   bun run install:all
   ```

3. Create a `.env` file in the root directory:
   ```bash
   cp .env.example .env
   ```

4. Add your OpenAI API key to the `.env` file:
   ```
   OPENAI_API_KEY=sk-your-api-key-here
   ```

### Development

Run both the server and client concurrently:

```bash
bun run dev
```

This will start:
- Backend server on `http://localhost:3001`
- Frontend dev server on `http://localhost:5173`

### Individual Commands

```bash
# Run only the backend
bun run dev:server

# Run only the frontend
bun run dev:client

# Build for production
bun run build
```

## Project Structure

```
ai-assistant/
â”œâ”€â”€ client/                 # Vite + React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â”œâ”€â”€ App.tsx        # Main app component
â”‚   â”‚   â”œâ”€â”€ main.tsx       # Entry point
â”‚   â”‚   â””â”€â”€ types.ts       # TypeScript types
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ tailwind.config.js
â”œâ”€â”€ server/                 # Bun backend
â”‚   â””â”€â”€ index.ts           # Server with /api/chat endpoint
â”œâ”€â”€ .env.example
â”œâ”€â”€ package.json           # Root scripts
â””â”€â”€ README.md
```

## API

### POST /api/chat

Send messages to the AI and receive streaming responses.

**Request Body:**
```json
{
  "messages": [
    { "role": "user", "content": "Hello!" }
  ],
  "systemPrompt": "You are a helpful assistant." // optional
}
```

**Response:** Server-Sent Events stream with chunks in format:
```
data: {"content":"Hello"}

data: {"content":" there!"}

data: [DONE]
```

## License

MIT
